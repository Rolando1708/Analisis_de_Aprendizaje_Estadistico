{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58182883-edf4-410e-9fb5-3cc408d49dfb",
   "metadata": {},
   "source": [
    "# Examen modulo 2\n",
    "\n",
    "\n",
    "## **Sección 1: Regresión Logística** (30 puntos)  \n",
    "\n",
    "1. **(10 pts)** Explica la diferencia entre la regresión logística **lineal** y la **polinomial**. ¿En qué casos es recomendable usar la versión polinomial?  \n",
    "\n",
    "La regresión logistica lineal basicamente separa los datos con una linea recta y hace una combinacion lineal de los datos, mientras que en una regresion logistica polinomial lo que hace es encontrar relaciones no lineales entre los datos. Es recomendable utilizar la regrresión logistica polinomial cuando los datos no tienen una relacion lineal \n",
    "\n",
    "\n",
    "2. **(10 pts)** Explica como mediante decenso en gradiente y maxima verosimilitud creamos una regresión lógisitca  \n",
    "\n",
    "Para poder calcular la probabilidad en una regresion logistica es de la siguiente manera:\n",
    "\n",
    "$$\n",
    "p(y = 1 | X) = \\sigma(\\theta^T X) = \\frac{1}{1 + e^{-\\theta^T X}}\n",
    "$$\n",
    "\n",
    "Como la variable y sigue una distribucion de Bernoulli, la funcion de verosimilitud es la siguiente:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "Se toma el logaritmo de esta funcion para poder maximizar la verosimilitud:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Y por ultimo para la función de perdida, se maximiza la log-verosmilitud:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "3. **(10 pts)** Explica el concepto de **odds** y **log-odds** en regresión logística. ¿Por qué la regresión logística predice el **log-odds** en lugar de la probabilidad directamente? Justifica esto \n",
    "\n",
    "Los odds son la probabilidad de ganar entre la probabilidad de perder \n",
    "\n",
    "$$ odds = \\frac{p}{1-p} $$\n",
    "\n",
    "y log odds es aplicarle logaritmo a estos odds, para poder estabilizarlos y que se encuentren un rango mas pequeño, que ayuda a mejorar el modelo y sus predicciones\n",
    "\n",
    "$$ ln(odds)=ln(\\frac{p}{1-p}) $$\n",
    "\n",
    "\n",
    "## **Sección 2: Área Bajo la Curva (AUC)** (20 puntos)  \n",
    "\n",
    "7. **(5 pts)** Define la **curva ROC** y el AUC. ¿Qué tiene de especial\n",
    "\n",
    "La curva ROC es la representación visual del rendimiento del modelo en todos los umbrales, en la grafica se muestra una relacion entre la sensibilidad y la specificity \n",
    "\n",
    "El AUC es el area que existe debajo de esta curva que indica la probabilidad de predicción de modelo entre las clases.\n",
    "\n",
    "\n",
    "8. **(5 pts)** Cuando hacemos una curva ROC, siempre ponemos una diagonal, explica que es esa diagonal  \n",
    "\n",
    "Esta diagonal basicamente divide el area en dos de manera equitativa, 0.5 en una parte del area y 0.5 en otra parte, lo cual representa un model que haga clasificacion de manera aleatoria que no tenga capacidad de clasificacion.\n",
    "\n",
    "9. **(5 pts)** Un modelo tiene un **AUC de 0.85**. Explica qué significa esto en términos de su capacidad de clasificación.  \n",
    "\n",
    "Esto nos quiere deicr que un modelo que tiene un AUC de 0.85, es que existe un 85% de que un sujeto que pertenece a la clase 1, tenga una predicción mayor de pertenecer a esa clase que un sujeto que pertenece a la clase 0.\n",
    "\n",
    "10. **(5 pts)** Un modelo tiene accuracy de 99% pero AUC de 0.5%, ¿Cómo es que esto podría suceder?\n",
    "\n",
    "\n",
    "## **Sección 3: Análisis del Discriminante Lineal (LDA)** (10 puntos)  \n",
    "\n",
    "11. **(10 pts)** ¿Qué es el análisis del discriminante lineal? ¿En que casos lo usarías? (gausiano)\n",
    "\n",
    "El analisis del discriminante lineal es un metodo de clasificacion el cual asume que los datos cada una de las clases siguen una distribución normal multivariada de la siguiente manera: \n",
    "\n",
    "$$\n",
    "     P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Para poder clasificar un nuevo o un nuevo punto se utiliza la regla de Bayes para poder calcular la probabilidad de la siguiente manera:\n",
    "\n",
    "$$\n",
    "     P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Una vez calculada la probabilidad el nuevo dato es asignado a la clase k siendo la que maximiza la probabilidad $P(y = k | \\mathbf{x})$\n",
    "\n",
    "El analisis del discriminante lineal es bastante util para cuando los datos de las clases siguen una distribución normal multivariada ya que los datos se clasificarian de mejor manera\n",
    "    \n",
    "\n",
    "## Sección 4: Cross validation  (10 puntos)  \n",
    "\n",
    "12. **(10 pts)** ¿Qué es grid search? ¿qué es random search? Explica las diferencias y cuando usarías cada uno \n",
    "\n",
    "Cuando se utiliza el grid search se estan utilizando todas las combinaciones posibles de hiperparametros de una grilla lo que es bastante bueno ya que al utilziar todas las combinaciones posibles te va termianr dando la mejor posible, lo malo es que al hacer todas las combinaciones posbiles es bastante costoso y tardado, a diferencia del random search donde en este hay un rango o un limite de valores aleatorios a utilizar, lo cual ayuda en el sentido en el que es más rapido que Grid Search y menos costoso, pero al ponerle un rango es altamente probable que no te de la mejor combinacion posible. Grid Search seria utilizado cuando tienes pocos hiperparametros o pocos datos seria mejor utilizar este ya que no tardaria tanto en correr y te daria la mejor combinacion posible, para el Random Search cuando tienes muchos hiperparametros o datos, seria mejor utilizarlo para que no se tarde tanto en correr.\n",
    "\n",
    "## **Sección 5: Redes Neuronales y Perceptrón Multicapa** (20 puntos)  \n",
    "\n",
    "13. **(5 pts)** Explica que es una red neuronal, que hace, como funciona, etc.\n",
    "\n",
    "Una red neuronal es un algoritmo donde existen diferentes capas con neuronas, que utiliza combinaciones lineales y funciones de activación para poder encontrar relaciones complejas entre los datos, primero se aplica forward propagation donde la primera capa es la capa de entrada donde se encuentran los datos iniciales, de ahí estos datos pasan a una capa oculta donde se realiza un calculo lineal y se aplica una función de activación, despues estos nuevos datos de esta capa pueden pasar a otra capa oculta donde hay mas neuronas y se vuelve a hacer el procedimiento de el calculo lineal y aplicar funcion de activación asi hasta llegar a la capa de salida donde se vuelve a hacer el mismo proceso pero ahora esta ultima capa te da un predicción despues de haber pasado por las capas seleccionadas.\n",
    " \n",
    "14. **(5 pts)** ¿Cuál es el propósito de la **backpropagation** en el entrenamiento de redes neuronales?  \n",
    "\n",
    "El backpropagation es un algoritmo que es utilizado despues de hacer el forward propagation donde lo que hace es calcular el error del modelo después de hacer forward propagation y lo que se hace es propagar el error ahora desde la capa de salida hasta la capa de entrada para poder distribuir el error calculado a todas las neuronas utilizadas en las capas, esto permite minimizar el error del modelo y que la red pueda mejorar su predicción\n",
    "\n",
    "15. **(5 pts)** A grandes rasgos, explica como obtenemos los coeficientes de una red neuronal  \n",
    "\n",
    "Una vez que es realizado el forward y back propagation los coeficientes se calculan con un factor de aprendizaje $ \\alpha{} $:\n",
    "\n",
    "$$\n",
    "   W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "   $$\n",
    "   $$\n",
    "   b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "Donde se restan los pesos menos los gradientes de la función de costos de los pesos que estan multiplicado por un factor de aprendizaje $ \\alpha{} $ y de igual manera para los sesgos, esto es repetido para cada capa lo que hace que vaya ajustando los coeficientes poco poco y asi poder reducir la funcion de costo.\n",
    "\n",
    "## **Sección 6: Softmax** (10 puntos)  \n",
    "16. **(5 pts)** Explica que es softmax, para que sirve y como se calcula\n",
    "\n",
    "A diferencia de una regresión logistica en la que solo se clasifica en dos clases siendo 0 y 1, un softmax se utiliza para poder clasificar a más de dos clases, dandole su probabilidad a cada una de estas clases.\n",
    "\n",
    "Para calccularlo se utiliza la siguiente funcion:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n",
    "Siendo k el numero de la clase a calcular, y siendo lo de adentro del exponencial el logit de cada clase, para cada clase se hace una división donde el numerador es un exponencial al logit de esa clase que se quiere calcular dividido entre la suma de todos los exponenciales, esto para normalizar y para que las probabilidades de cada clase sumen 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## **Puntaje Total: 100 puntos**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1178f20-e11d-4c3b-8966-83f05be61004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
