{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Values\n",
    "\n",
    "Se sacan las permutaciones posibles de las variables del dataset, se calcula la contribución mrginal de cada una de las variables en cada permutación.\n",
    "\n",
    "Se promedian las contribuciones marginales de cada variable para obtener el shap value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribución Marginal\n",
    "\n",
    "Es cuanto cambia la predicción de un modelo cuando esa variable se agrega a unas que ya se conocen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans\n",
    "\n",
    "Es un algoritmo de aprendizaje el cual se utiliza para resolver problemas de clustering, donde divide los conjuntos de datos de manera que se parezcan lo mas posible entre si. Si se tienen muchos puntos dispersos para poder agruparlos primero se inicializa K centroides de manera aleatoria, asigna cada punto en el centro mas cercano y por ultimo recalcula los centroides como el promedio de los puntos asignados a cada grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "Técnica que busca disminuir la dimensionalidad de un conjunto de datos, manteniendo la mayor cantidad de varianza posible. Para esto se necesita la proyección del componente:\n",
    "\n",
    "$$\\text{Proy}_{u_1}(x_i) = u_1^T x_i$$\n",
    "\n",
    "El objetivo es tener la cantidad de componentes que expliquen la mayor cantidad de varianza posible:\n",
    "\n",
    "$$\\text{Varianza} = \\frac{1}{N} \\sum_{n=1}^N \\left( u_1^T x_n - u_1^T \\bar{x} \\right)^2$$\n",
    "\n",
    "Finalmente, agrupando términos:\n",
    "\n",
    "$$= u_1^T S u_1$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $S$ es la matriz de covarianza de los datos.\n",
    "- $u_1$ indica la dirección del primer componente principal, es decir, la dirección donde los datos se extienden más.\n",
    "\n",
    "Se busca encontrar el vector $u_1$ que maximice la varianza de las proyecciones.\n",
    "\n",
    "$$\n",
    "\\max_{u_1} u_1^T S u_1\n",
    "$$\n",
    "\n",
    "sujeto a la restricción:\n",
    "\n",
    "$$\n",
    "\\|u_1\\| = 1\n",
    "$$\n",
    "\n",
    "Aplicando multiplicadores de Lagrange se tiene:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(u_1, \\lambda) = u_1^T S u_1 - \\lambda (u_1^T u_1 - 1)\n",
    "$$\n",
    "\n",
    "donde $\\lambda$ es el multiplicador de Lagrange.\n",
    "\n",
    "Derivamos respecto a $u_1$ y igualamos a cero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial u_1} = 2 S u_1 - 2 \\lambda u_1 = 0\n",
    "$$\n",
    "\n",
    "lo que se puede reorganizar como:\n",
    "\n",
    "$$\n",
    "S u_1 = \\lambda u_1\n",
    "$$\n",
    "\n",
    "Esto es un problema de eigenvalores donde $u_1$ es un eigenvector en una matriz de covarianza y $\\lambda$ es el eigenvalor. Los eigenvalores que se obtienen son los valores que maximizan la varianza asocidad al componente principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento Continuo S Learner\n",
    "\n",
    "Entrenas un modelo sobre sus datos originales. Despues defines sobre que variable se analiza su efecto. A la variable le das diferentes valores distintos e iterativamente usas el modelo para hacer predicciones con distintos valores y poder revisar el efecto que tiene a la hora de hacer la predicción.\n",
    "\n",
    "# CATE\n",
    "\n",
    "Efecto esperado del tratamiento para individuos con esa caracteristica\n",
    "\n",
    "# S Learner Discreto\n",
    "\n",
    "Entrenas el modelo con los datos originales, despues modificas los datos para que todos tengan el tratamiento 1 y también para que nadie tenga tratamiento 0, esto se utiliza para hacer predicciones, donde restas la diferencia de las predicciones con tratamiento menos las predicciones sin tratamiento, esta diferencia que da como resultado es el CATE de tener tratamiento\n",
    "\n",
    "# T Learner\n",
    "\n",
    "Los datos los modificas donde tengass dos datasets, uno donde el tratamiento es 1 y el otro donde es 0, es decir que nadie tiene el tratamiento. Con esos dos entrenas un modelo para cada uno. Despues usas ambos para hacer predicciones con tus datos originales. donde uno tiene sesgo hacia los que si tienene tratamiento y el otro donde hay sesgo a los que no tiene. Al final las predicciones que se realizaron en el modelo con tratamiento 1 le restas las predicciones del modelo con tratamiento 0 y esta diferencia es el CATE causado por el tratamiento.\n",
    "\n",
    "# X Learner \n",
    "\n",
    "Haces dos modelos al igual que en el modelo de T Learner con los modelos con tratamiento 1 y 0. Con los modelos calculas D0 Y D1, en D0 calculas lo que paso menos lo que pasaría sin tratiemnto donde a y_train le restas la predicción de model 0 usando su contrafactual.\n",
    "En el caso de D1 obitnes lo que habría pasado menos lo que paso, usando las predicciones del model 1 con los datos de su contrafactual menos lo que paso.\n",
    "\n",
    "Ya que tienes D0 y D1 se entrenan dos modelos nuevos los cuales se utilizan para hacer la prediccion del CATE (efecto causal) condicional dentro de cada grupo, para poder hacerlo entrenas md0 con los datos con tratamiento como X y D0 como y y de forma inversa entrenas md1 con los datos sin tratamiento como X y D1 como y.\n",
    "\n",
    "Por ultimo se necesita calular el propensity scor, que te da la probabilidad de tener el tratamiento condicional a X. Para lograr esto se calcular un modelo de clasificación donde tus valores originales son la X y la y para cuando tienen tratamiento o no. usas md0 y md1 para obtener los CATE y con el propensity score ya calculado ponderas el CATE para darle el peso correspondiento dada la probabilidad de tener o no el tratamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
